{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyPIe5s9kNKyNffzJeiBRx4c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"neZUZlSyukCP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685348015112,"user_tz":-480,"elapsed":47243,"user":{"displayName":"Qingchen Yu","userId":"04939759337865835465"}},"outputId":"c840a4b2-4ef3-4886-c195-a1768ff3f458"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/Colab_Notebook/ChatBotX/ . -r"],"metadata":{"id":"nXsIRcz1waTa","executionInfo":{"status":"ok","timestamp":1685348043889,"user_tz":-480,"elapsed":26227,"user":{"displayName":"Qingchen Yu","userId":"04939759337865835465"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["%cd ./ChatBotX/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dDBnQFtc8QdX","executionInfo":{"status":"ok","timestamp":1685348043890,"user_tz":-480,"elapsed":10,"user":{"displayName":"Qingchen Yu","userId":"04939759337865835465"}},"outputId":"765cb32f-1c03-4c5d-c856-61e0aeafb44a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ChatBotX\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"He1CSQXp8Vwn","executionInfo":{"status":"ok","timestamp":1685348043890,"user_tz":-480,"elapsed":8,"user":{"displayName":"Qingchen Yu","userId":"04939759337865835465"}},"outputId":"bc4dd51d-323a-4d8e-a51c-728a83c36807"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["chat.py    data_processing.py  README.md\t   transformer.py\n","config.py  LICENSE\t       train_helper.ipynb  utils.py\n","data\t   __pycache__\t       train.py\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O4rMyObZ6RNT","executionInfo":{"status":"ok","timestamp":1685348043891,"user_tz":-480,"elapsed":6,"user":{"displayName":"Qingchen Yu","userId":"04939759337865835465"}},"outputId":"cce44784-564d-4ddd-d669-52a1b31712d8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon May 29 08:14:03 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    24W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["!python train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nH4LqgHD7mf2","outputId":"01e2949f-5d39-452e-849a-b6c4aba1864f","executionInfo":{"status":"ok","timestamp":1685352320292,"user_tz":-480,"elapsed":4243239,"user":{"displayName":"Qingchen Yu","userId":"04939759337865835465"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-29 08:14:37.287100: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-29 08:14:38.337008: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-05-29 08:14:40.403390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-29 08:14:41.006383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-29 08:14:41.006672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-29 08:14:41.014236: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-29 08:14:41.014534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-29 08:14:41.014745: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-29 08:14:43.621634: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-29 08:14:43.621945: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-29 08:14:43.622128: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-29 08:14:43.622264: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-05-29 08:14:43.622313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14504 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n","Building prefix dict from the default dictionary ...\n","Dumping model to file cache /tmp/jieba.cache\n","Loading model cost 0.652 seconds.\n","Prefix dict has been built successfully.\n","Epoch 1/5:   0% 0.00/3.55k [00:00<?, ?it/s]2023-05-29 08:16:12.949315: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fbcfd1e2830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-05-29 08:16:12.949370: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n","2023-05-29 08:16:13.090570: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2023-05-29 08:16:13.742399: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n","2023-05-29 08:16:14.223777: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","Epoch 1/5: 100% 3.55k/3.55k [15:13<00:00, 3.88it/s, Loss=0.0302, Accuracy=0.958]\n","Epoch 1 Loss 0.0299 Accuracy 0.9587\n","Time taken for 1 epoch: 913.2977492809296 secs\n","\n","Epoch 2/5: 100% 3.55k/3.55k [13:31<00:00, 4.37it/s, Loss=0.00529, Accuracy=0.976]\n","Epoch 2 Loss 0.0053 Accuracy 0.9757\n","Time taken for 1 epoch: 811.5149986743927 secs\n","\n","Epoch 3/5: 100% 3.55k/3.55k [13:31<00:00, 4.37it/s, Loss=0.00477, Accuracy=0.978]\n","Epoch 3 Loss 0.0048 Accuracy 0.9775\n","Time taken for 1 epoch: 811.7892596721649 secs\n","\n","Epoch 4/5: 100% 3.55k/3.55k [13:31<00:00, 4.37it/s, Loss=0.00454, Accuracy=0.978]\n","Epoch 4 Loss 0.0045 Accuracy 0.9784\n","Time taken for 1 epoch: 811.4056828022003 secs\n","\n","Epoch 5/5: 100% 3.55k/3.55k [13:31<00:00, 4.37it/s, Loss=0.0044, Accuracy=0.979]\n","Epoch 5 Loss 0.0044 Accuracy 0.9789\n","Time taken for 1 epoch: 811.3160707950592 secs\n","\n"]}]},{"cell_type":"code","source":["!cp -r /content/ChatBotX/saved_models /content/drive/MyDrive/Colab_Notebook/ChatBotX/"],"metadata":{"id":"j8RWfWRTpNiG","executionInfo":{"status":"ok","timestamp":1685352320900,"user_tz":-480,"elapsed":612,"user":{"displayName":"Qingchen Yu","userId":"04939759337865835465"}}},"execution_count":7,"outputs":[]}]}