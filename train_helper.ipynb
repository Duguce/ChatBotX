{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyMO+xg945grNkSTRa7rqkg3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"neZUZlSyukCP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684906128287,"user_tz":-480,"elapsed":20425,"user":{"displayName":"Qingchen Yu","userId":"04939759337865835465"}},"outputId":"f4a6db8f-e9b7-41fa-c97d-2b2dc8adc7f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/Colab_Notebook/ChatBotX/ . -r"],"metadata":{"id":"nXsIRcz1waTa","executionInfo":{"status":"ok","timestamp":1684906143926,"user_tz":-480,"elapsed":15644,"user":{"displayName":"Qingchen Yu","userId":"04939759337865835465"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["%cd ./ChatBotX/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dDBnQFtc8QdX","executionInfo":{"status":"ok","timestamp":1684906143926,"user_tz":-480,"elapsed":15,"user":{"displayName":"Qingchen Yu","userId":"04939759337865835465"}},"outputId":"6402bd63-5ba8-4f1d-b42c-c78a79782ee1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ChatBotX\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"He1CSQXp8Vwn","executionInfo":{"status":"ok","timestamp":1684906143927,"user_tz":-480,"elapsed":13,"user":{"displayName":"Qingchen Yu","userId":"04939759337865835465"}},"outputId":"a5d2cf9c-6aba-494b-fbe0-f7dd237920f8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["config.py  data_processing.py  __pycache__  train_helper.ipynb\ttransformer.py\n","data\t   LICENSE\t       README.md    train.py\t\tutils.py\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O4rMyObZ6RNT","executionInfo":{"status":"ok","timestamp":1684906143927,"user_tz":-480,"elapsed":8,"user":{"displayName":"Qingchen Yu","userId":"04939759337865835465"}},"outputId":"4c678ec2-bd5c-46d5-ebd7-6fbec959c335"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed May 24 05:29:03 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    24W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["!python ./train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nH4LqgHD7mf2","outputId":"64b5df58-690f-4dc7-9762-41b19fcde945","executionInfo":{"status":"ok","timestamp":1684914463808,"user_tz":-480,"elapsed":1252352,"user":{"displayName":"Qingchen Yu","userId":"04939759337865835465"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-24 05:29:10.514218: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-24 05:29:12.103367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-05-24 05:29:14.851916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-24 05:29:15.377173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-24 05:29:15.377554: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-24 05:29:15.384332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-24 05:29:15.384641: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-24 05:29:15.384844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-24 05:29:17.983739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-24 05:29:17.984012: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-24 05:29:17.984196: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-24 05:29:17.984328: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-05-24 05:29:17.984375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14518 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n","Building prefix dict from the default dictionary ...\n","Dumping model to file cache /tmp/jieba.cache\n","Loading model cost 1.082 seconds.\n","Prefix dict has been built successfully.\n","Epoch 1/10:   0% 0.00/3.55k [00:00<?, ?it/s]2023-05-24 05:30:49.459706: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f76c1990150 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-05-24 05:30:49.459760: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n","2023-05-24 05:30:49.594632: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2023-05-24 05:30:50.366001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n","2023-05-24 05:30:50.997032: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","Epoch 1/10: 100% 3.55k/3.55k [15:16<00:00, 3.87it/s, Loss=0.0294, Accuracy=0.958]\n","Epoch 1 Loss 0.0291 Accuracy 0.9586\n","Time taken for 1 epoch: 916.9492292404175 secs\n","\n","Epoch 2/10: 100% 3.55k/3.55k [13:32<00:00, 4.37it/s, Loss=0.00528, Accuracy=0.976]\n","Epoch 2 Loss 0.0053 Accuracy 0.9758\n","Time taken for 1 epoch: 812.08154296875 secs\n","\n","Epoch 3/10: 100% 3.55k/3.55k [13:32<00:00, 4.36it/s, Loss=0.00477, Accuracy=0.978]\n","Epoch 3 Loss 0.0048 Accuracy 0.9776\n","Time taken for 1 epoch: 812.7089936733246 secs\n","\n","Epoch 4/10: 100% 3.55k/3.55k [13:32<00:00, 4.37it/s, Loss=0.00454, Accuracy=0.978]\n","Epoch 4 Loss 0.0045 Accuracy 0.9784\n","Time taken for 1 epoch: 812.5998458862305 secs\n","\n","Epoch 5/10: 100% 3.55k/3.55k [13:33<00:00, 4.36it/s, Loss=0.0044, Accuracy=0.979]\n","Epoch 5 Loss 0.0044 Accuracy 0.9789\n","Time taken for 1 epoch: 813.0326614379883 secs\n","\n","Epoch 6/10: 100% 3.55k/3.55k [13:30<00:00, 4.37it/s, Loss=0.0043, Accuracy=0.979]\n","Epoch 6 Loss 0.0043 Accuracy 0.9793\n","Time taken for 1 epoch: 810.9117348194122 secs\n","\n","Epoch 7/10: 100% 3.55k/3.55k [13:30<00:00, 4.38it/s, Loss=0.00423, Accuracy=0.98]\n","Epoch 7 Loss 0.0042 Accuracy 0.9796\n","Time taken for 1 epoch: 810.6904675960541 secs\n","\n","Epoch 8/10: 100% 3.55k/3.55k [13:30<00:00, 4.38it/s, Loss=0.00418, Accuracy=0.98]\n","Epoch 8 Loss 0.0042 Accuracy 0.9798\n","Time taken for 1 epoch: 810.389710187912 secs\n","\n","Epoch 9/10: 100% 3.55k/3.55k [13:31<00:00, 4.37it/s, Loss=0.00413, Accuracy=0.98]\n","Epoch 9 Loss 0.0041 Accuracy 0.9800\n","Time taken for 1 epoch: 811.5806312561035 secs\n","\n","Epoch 9/10: 100% 3.55k/3.55k [13:31<00:00, 4.37it/s, Loss=0.00413, Accuracy=0.98]\n","Epoch 9 Loss 0.0041 Accuracy 0.9800\n","Time taken for 1 epoch: 811.5806312561035 secs\n","\n","Epoch 9/10: 100% 3.55k/3.55k [13:31<00:00, 4.37it/s, Loss=0.00413, Accuracy=0.98]\n","Epoch 9 Loss 0.0041 Accuracy 0.9800\n","Time taken for 1 epoch: 811.5806312561035 secs\n","\n","Epoch 9/10: 100% 3.55k/3.55k [13:31<00:00, 4.37it/s, Loss=0.00413, Accuracy=0.98]\n","Epoch 9 Loss 0.0041 Accuracy 0.9800\n","Time taken for 1 epoch: 811.5806312561035 secs\n","\n","Epoch 10/10: 100% 3.55k/3.55k [13:32<00:00, 4.37it/s, Loss=0.00409, Accuracy=0.98]\n","Epoch 10 Loss 0.0041 Accuracy 0.9801\n","Time taken for 1 epoch: 812.4711322784424 secs\n","\n","Epoch 10/10: 100% 3.55k/3.55k [13:32<00:00, 4.37it/s, Loss=0.00409, Accuracy=0.98]\n","Epoch 10 Loss 0.0041 Accuracy 0.9801\n","Time taken for 1 epoch: 812.4711322784424 secs\n","\n","Epoch 10/10: 100% 3.55k/3.55k [13:32<00:00, 4.37it/s, Loss=0.00409, Accuracy=0.98]\n","Epoch 10 Loss 0.0041 Accuracy 0.9801\n","Time taken for 1 epoch: 812.4711322784424 secs\n","\n","Epoch 10/10: 100% 3.55k/3.55k [13:32<00:00, 4.37it/s, Loss=0.00409, Accuracy=0.98]\n","Epoch 10 Loss 0.0041 Accuracy 0.9801\n","Time taken for 1 epoch: 812.4711322784424 secs\n","\n"]}]},{"cell_type":"code","source":["!cp -r /content/ChatBotX/saved_models /content/drive/MyDrive/Colab_Notebook/ChatBotX/"],"metadata":{"id":"j8RWfWRTpNiG","executionInfo":{"status":"ok","timestamp":1684914473990,"user_tz":-480,"elapsed":4194,"user":{"displayName":"Qingchen Yu","userId":"04939759337865835465"}}},"execution_count":7,"outputs":[]}]}